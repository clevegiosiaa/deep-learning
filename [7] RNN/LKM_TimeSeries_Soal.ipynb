{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89e49371",
   "metadata": {},
   "source": [
    "# Prediksi Time-Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af8dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b85d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_prob):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        # Defining the number of layers and the nodes in each layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # RNN layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initializing hidden state for first input with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()\n",
    "\n",
    "        # Forward propagation by passing in the input and hidden state into the model\n",
    "        out, h0 = self.rnn(x, h0.detach())\n",
    "\n",
    "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
    "        # so that it can fit into the fully connected layer\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "input_size = 1\n",
    "hidden_size = 1\n",
    "num_layers = 1\n",
    "num_classes = 1\n",
    "dropout_prob = 0.5\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes, dropout_prob)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efc236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_prob):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        \n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        \n",
    "        out = self.fc(h_out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "input_size = 1\n",
    "hidden_size = 1\n",
    "num_layers = 1\n",
    "num_classes = 1\n",
    "dropout_prob = 0.5\n",
    "\n",
    "model = LSTM(input_size, hidden_size, num_layers, num_classes, dropout_prob)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1078f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout_prob):\n",
    "        super(GRU, self).__init__()\n",
    "\n",
    "        # Defining the number of layers and the nodes in each layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initializing hidden state for first input with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()\n",
    "\n",
    "        # Forward propagation by passing in the input and hidden state into the model\n",
    "        out, _ = self.gru(x, h0.detach())\n",
    "\n",
    "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
    "        # so that it can fit into the fully connected layer\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "input_size = 1\n",
    "hidden_size = 1\n",
    "num_layers = 1\n",
    "num_classes = 1\n",
    "dropout_prob = 0.5\n",
    "\n",
    "model = GRU(input_size, hidden_size, num_layers, num_classes, dropout_prob)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9215dba8",
   "metadata": {},
   "source": [
    "# Melbourne Temperature (1981-1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e42ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "input_size, hidden_size, output_size = 7, 6, 1\n",
    "epochs = 300\n",
    "lr = 0.1\n",
    "ts_data = pd.read_csv(\"melbourne_temperature_1981-1990.txt\")\n",
    "data = np.array(ts_data['Temp'])\n",
    "seq_length = len(data)-1\n",
    "data_time_steps = np.array(ts_data.index)\n",
    "data.resize(len(data), 1)\n",
    "\n",
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1962c22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        _x = data[i:(i+seq_length)]\n",
    "        _y = data[i+seq_length]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return np.array(x),np.array(y)\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "training_data = sc.fit_transform(data)\n",
    "\n",
    "seq_length = 10\n",
    "x, y = sliding_windows(training_data, seq_length)\n",
    "\n",
    "train_size = int(len(y) * 0.8)\n",
    "test_size = len(y) - train_size\n",
    "\n",
    "dataX = Variable(torch.Tensor(np.array(x)))\n",
    "dataY = Variable(torch.Tensor(np.array(y)))\n",
    "\n",
    "trainX = Variable(torch.Tensor(np.array(x[0:train_size])))\n",
    "trainY = Variable(torch.Tensor(np.array(y[0:train_size])))\n",
    "\n",
    "testX = Variable(torch.Tensor(np.array(x[train_size:len(x)])))\n",
    "testY = Variable(torch.Tensor(np.array(y[train_size:len(y)])))\n",
    "\n",
    "plt.plot(trainX[:,0,0].numpy())\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(trainY[:,0].numpy())\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(testX[:,0,0].numpy())\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(testY[:,0].numpy())\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661ea5a9",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081afdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 1\n",
    "num_layers = 1\n",
    "num_classes = 1\n",
    "dropout_prob = 0.5\n",
    "# model = \n",
    "\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(trainX).mean(1).unsqueeze(1)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # obtain the loss function\n",
    "    # backpropagation\n",
    "    # update parameter\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n",
    "        \n",
    "print(model.eval())\n",
    "train_predict = model(dataX).mean(1).unsqueeze(1)\n",
    "\n",
    "data_predict = train_predict.data.numpy()\n",
    "dataY_plot = dataY.data.numpy()\n",
    "\n",
    "data_predict = sc.inverse_transform(data_predict)\n",
    "dataY_plot = sc.inverse_transform(dataY_plot)\n",
    "\n",
    "print('mean absolute error test = ', mean_absolute_error(dataY_plot, data_predict))\n",
    "\n",
    "plt.axvline(x=train_size, c='r', linestyle='--')\n",
    "\n",
    "plt.plot(dataY_plot)\n",
    "plt.plot(data_predict)\n",
    "plt.suptitle('Temperature Prediction')\n",
    "plt.ylabel('Temperature')\n",
    "plt.xlabel('Days')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef00a907",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917fa511",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 1\n",
    "num_layers = 1\n",
    "num_classes = 1\n",
    "dropout_prob = 0.5\n",
    "# model =\n",
    "\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(trainX).mean(1).unsqueeze(1)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # obtain the loss function\n",
    "    # backpropagation\n",
    "    # update parameter\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n",
    "        \n",
    "print(model.eval())\n",
    "train_predict = model(dataX).mean(1).unsqueeze(1)\n",
    "\n",
    "data_predict = train_predict.data.numpy()\n",
    "dataY_plot = dataY.data.numpy()\n",
    "\n",
    "data_predict = sc.inverse_transform(data_predict)\n",
    "dataY_plot = sc.inverse_transform(dataY_plot)\n",
    "\n",
    "print('mean absolute error test = ', mean_absolute_error(dataY_plot, data_predict))\n",
    "\n",
    "plt.axvline(x=train_size, c='r', linestyle='--')\n",
    "\n",
    "plt.plot(dataY_plot)\n",
    "plt.plot(data_predict)\n",
    "plt.suptitle('Temperature Prediction')\n",
    "plt.ylabel('Temperature')\n",
    "plt.xlabel('Days')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828307c7",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fffac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 1\n",
    "num_layers = 1\n",
    "num_classes = 1\n",
    "dropout_prob = 0.5\n",
    "# model = \n",
    "\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(trainX).mean(1).unsqueeze(1)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # obtain the loss function\n",
    "    # backpropagation\n",
    "    # update parameter\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n",
    "        \n",
    "print(model.eval())\n",
    "train_predict = model(dataX).mean(1).unsqueeze(1)\n",
    "\n",
    "data_predict = train_predict.data.numpy()\n",
    "dataY_plot = dataY.data.numpy()\n",
    "\n",
    "data_predict = sc.inverse_transform(data_predict)\n",
    "dataY_plot = sc.inverse_transform(dataY_plot)\n",
    "\n",
    "print('mean absolute error test = ', mean_absolute_error(dataY_plot, data_predict))\n",
    "\n",
    "plt.axvline(x=train_size, c='r', linestyle='--')\n",
    "\n",
    "plt.plot(dataY_plot)\n",
    "plt.plot(data_predict)\n",
    "plt.suptitle('Temperature Prediction')\n",
    "plt.ylabel('Temperature')\n",
    "plt.xlabel('Days')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d1a9e",
   "metadata": {},
   "source": [
    "# Sunspots (1749-1983)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "input_size, hidden_size, output_size = 7, 6, 1\n",
    "epochs = 300\n",
    "lr = 0.1\n",
    "ts_data = pd.read_csv(\"sunspots_1749-1983.txt\")\n",
    "data = np.array(ts_data['Sunspots'])\n",
    "data_time_steps = np.array(ts_data.index)\n",
    "data.resize((len(data), 1))\n",
    "\n",
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        _x = data[i:(i+seq_length)]\n",
    "        _y = data[i+seq_length]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    return np.array(x),np.array(y)\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "training_data = sc.fit_transform(data)\n",
    "\n",
    "seq_length = 10\n",
    "x, y = sliding_windows(training_data, seq_length)\n",
    "\n",
    "train_size = int(len(y) * 0.8)\n",
    "test_size = len(y) - train_size\n",
    "\n",
    "dataX = Variable(torch.Tensor(np.array(x)))\n",
    "dataY = Variable(torch.Tensor(np.array(y)))\n",
    "\n",
    "trainX = Variable(torch.Tensor(np.array(x[0:train_size])))\n",
    "trainY = Variable(torch.Tensor(np.array(y[0:train_size])))\n",
    "\n",
    "testX = Variable(torch.Tensor(np.array(x[train_size:len(x)])))\n",
    "testY = Variable(torch.Tensor(np.array(y[train_size:len(y)])))\n",
    "\n",
    "plt.plot(trainX[:,0,0].numpy())\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(trainY[:,0].numpy())\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(testX[:,0,0].numpy())\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(testY[:,0].numpy())\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d59785",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02432706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a8985c5",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5002d4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "712b962e",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5ce0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
